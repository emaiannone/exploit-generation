%! Author = emaia
%! Date = 10/03/20

% OSS diffusion
Almost all modern applications heavily rely on Open-Source Software (\textit{a.k.a.} OSS) libraries.
Some estimates say that 80\% to 90\% of software products on the market includes some OSS components.
Other estimates say that the OSS components distribution depends on the kind of application: for commercial ones we have
a distribution of 35\% of total codebase, while for internal use application we reach the 75\% ~\cite{open_source}.

% OSS is vulnerable
The usage of OSS libraries lowers the development costs and time-to-market at the price of relying of something not fully validated.
As time goes by, more and more vulnerabilities of popular OSS libraries are being discovered and reported in Common
Vulnerabilities and Exposures (\textit{a.k.a.} CVE) databases, like the National Vulnerability Database (\textit{a.k.a.} NVD)~\cite{nvd}.
This growing trend made in 2013 to label \textit{`Using OSS components with known vulnerabilities'} as one of the
\textit{OWASP Top 10 Application Security Risks}.

% Detection tools: mitigation
To tackle this problem, numerous vulnerability detection tools are available,
either as OSS or as commercial products~\cite{owasp_dc, whitesource, ponta2018icsme_beyond}.
They analyze a given project to assess whether it relies on vulnerable OSS components.
Whenever a vulnerability is detected, the typical mitigation is asking to update the vulnerable library into a non-vulnerable version.
This proposed action is acceptable for software under development that is far its first release because all the necessary
adaptations in the application code can be performed as part of the normal development.
On the other hand, updating a library is a risky action for software in production or near its first release
because the update might force to modify most of the API calls (\textit{e.g.,} when updating to a different major release)
and to run regression tests, implying extra time and efforts.
This is better explained in~\cite{kula2017ese_updates} where the developers perceives the library updates as an extra workload and responsibility.

% Detection tools: detection
Some of these detection tools (quali?) use a naive but simple approach: including a certain vulnerable version of an OSS library
(\textit{e.g.,} having a certain dependency in \textit{pom.xml}) flags the entire project as potentially vulnerable.
The main drawback of this detection is that the vulnerable code might not be reachable at all, leading to numerous false positives.
For this reason, other tools (quali? oltre Steady?) relies on static source code analysis, by checking whether a certain vulnerable construct
(\textit{i.e.,} a general definition for any programming construct, \textit{e.g.,} a statement, a branch, a method, a class, a module, etc.)
is reachable in the Control Flow Graph;
however, this does not guarantee that the vulnerable construct can be exploited to carry an attack.
For example, that construct may be guarded by a good sanitization routine that prevents the construct to receive any malevolent input.
In order to expand these kind of analysis, other tools apply a dynamic analysis alongside the static one by relying on the available test suite
and on runtime information;
moreover, tools like Steady~\cite{ponta2018icsme_beyond} further expands the reachable constructs by applying an additional static analysis
on top of the results produced by the dynamic one (\textit{e.g.,} to reach constructs
called by the code loaded through Java Reflection~\cite{landman2017_reflection}).
Unfortunately, not all applications have access to a good test suite and/or runtime information (qualcosa a supporto?),
in these cases only a simple static analysis is applicable;
besides, the available tools do not assess the complexity of exploitability of the vulnerable constructs, so
it is hard to say whether a construct is actually exploitable and how it is hard to generate a concrete attack (o malicious input?).
Recently, there has been some initial efforts in search-based, for example, \citeauthor{jan2019_xmli}
proposed a novel genetic algorithm that tries to generate a set of malicious user inputs
for exploiting XML Injections~\cite{jan2019_xmli} in web applications.
However, this solution has some limitations: (i) it only works for a particular kind of vulnerability (\textit{i.e.,} XML Injections),
(ii) it only focuses on a precise set of vulnerable messages and (iii) it treats the SUT as a black-box, without
looking at the code nor at its API, so it does not know the concept of vulnerable construct.

% Proposal
In this work we propose a novel search-based technique that combines the efforts of Steady and Evosuite~\cite{fraser2013_evosuite} by
providing an additional coverage criteria for the latter to produce a test suite that exploits, at its best, the given vulnerabilities.
Whenever the generation fails to cover certain vulnerabilities, the technique gives some measures on the exploitability
of the given goals.

% Metto questo?
%- Some tools relies on metadata associated to OSS libraries, so basing their analysis on a detailed description of the vulnerability (affected components, steps to reprocude, and so on).
%  - Problem: metadata not always clear or available.

%! Author = emaia
%! Date = 10/03/20

\textbf{WORK IN PROGRESS SECTION}

In this section we explain the novel search algorithm used for the automatic generation of exploit test cases.

\subsection{Preliminary Assumptions}\label{subsec:assumptions}
% Dataset
\textbf{Should I explain the dataset here or in another section when presenting the validation?}
We chose to analyze the vulnerabilities of well-known OSS Java libraries and frameworks (\textit{e.g.,} Spring, Jenkins, Spark, Kafka).
Their vulnerabilities are publicly disclosed as CVE and collected in the NVD. In particular \citeauthor{ponta2019msr_dataset},
defined and made available a manually-curated dataset of fixes of these known
vulnerabilities~\cite{ponta2019msr_dataset}.
This dataset maps for each CVE entry the related repository URL and the signature of the fix commit
(\textit{i.e.,} the commit that officially patches the vulnerability).
So, the dataset has the form of a set of triples \textit{(CVE\_entry, repository\_url, fix\_commit\_hash)}, for example
(CVE-2017-4971, \url{https://github.com/spring-projects/spring-webflow}, 57f2ccb66946943fbf3b3f2165eac1c8eb6b1523).
Each fix commit is very different: some of them only apply changes on few lines in a single class, while others
consists of addition and refactoring of methods in various classes. (\textbf{I don't like this sentence})
We are interested in understanding the set of vulnerable constructs (\textit{i.e.,} the set of fixed constructs),
because we want to analyze the various forms of vulnerabilities to find a common representation that is suitable for the search algorithm.

% Assumptions
We chose to focus on what we consider the most simple type of vulnerable construct, that is the vulnerable line (\textit{i.e., }
a source code line that an attacker can exploit by giving it a certain malicious input), so the proposed coverage criterion is a
variation of the line coverage one.
When this approach will be mature enough, we will extend it to other types of vulnerabilities.

% Evosuite: why extend
We chose to implement this novel algorithm as an extension of \textsc{EvoSuite}~\cite{fraser2013_evosuite},
an automatic \textit{JUnit} tests generator for \textit{Java} classes by using a whole suite evolutionary approach
to derive the best possible test suites (\textit{i.e.,} covering all feasible goals and having the minimal number of total statements).
\textsc{EvoSuite} is a fully fledged GA framework, so it allows to (i) add new coverage criteria,
(ii) add new genetic operators (\textit{i.e.,} selection, crossover and mutation), (iii) reuse well-validated meta-heuristics and
(iv) reuse the instrumentation and program analysis tools, such as Control Flow Graphs, Call Graphs and Execution Traces.
It is possible to extend \textsc{EvoSuite} by adding some classes (related to the new coverage criteria and genetic operators),
and make small changes in others.
Sections~\ref{subsec:goals},~\ref{subsec:fitness} and~\ref{subsec:operators} provides additional details on the search algorithm.
In the context of our work we are not generating tests in the narrow sense (\textit{i.e.,} program execution that verifies a certain
expected behaviour) but `exploits cases', so we disabled the assert generation engine \textbf{Are we sure it can be disabled?}.

\subsection{Coverage Goals}\label{subsec:goals}
The approach is able to work on multiple coverage goals in a single run.
A coverage goal is defined from a triple of strings \textsc{(vulnerable\_class}, \textsc{vulnerable\_method},
\textsc{vulnerable\_line}) where \textsc{vulnerable\_class} is the fully-qualified name of the vulnerable class (\textit{e.g.,}
\sloppy\textit{\url{org.springframework.webflow.mvc.view.AbstractMvcView}}), \textsc{vulnerable\_method} is the name of the vulnerable
method concatenated with its descriptor (\textit{e.g.,}
\sloppy\textit{\url{addEmptyValueMapping(Lorg/springframework/binding/mapping/impl/DefaultMapper;Ljava/lang/String;Ljava/lang/Object;)V}})
and \textsc{vulnerable\_line} is the number of the vulnerable line in the source code.
The strings \textsc{vulnerable\_class} and \textsc{vulnerable\_method} are used to determine the right \textit{call context},
\textit{i.e.,} the list of method calls from the class under test (CUT) needed to reach the vulnerable method in the vulnerable class;
the string \textsc{vulnerable\_line} is used to retrieve the list of control dependencies on the vulnerable line
(\textit{i.e.,} predicates to be satisfied in order to certainly execute that line).

In other words, each coverage goal is composed of (i) a call context to reach a certain vulnerable method and
(ii) the list of control dependencies needed to execute vulnerable line.
An individual (test suite) covers a goal whenever it has a test case whose execution trace covers the call context and all
control dependencies in the list.

\textbf{Currently, I tried with only a single hard-coded goal per run.
The next steps will be (i) find a way to create the goal without hard-coding and (ii) try the approach with multiple goals}

\subsection{Fitness Function}\label{subsec:fitness}
\textbf{Primitive idea, I haven't tested so much, don't take too seriously the numbers.
I will use smarter formulas once I have a stable idea}

The fitness score is computed for each pair (test case, target goal) and it is based on the concepts
of \textit{context similarity} and \textit{approach level}:

\textbf{Improve these definitions and labels and user more formulas and less words}

\begin{definition}
    Given two call contexts $a$ and $t$, the \textit{context similarity} is the ratio of the number of method calls
    that $a$ and $t$ have in common to the total number of the longest call context.
\end{definition}

\begin{definition}
    Given an execution trace $e$ and a branch $b$, the \textit{approach level} is the number of
    control dependencies between $b$ and the executed branch that is closes to $b$.
\end{definition}

Based on these definitions, we define:

\begin{definition}
    Given a set of call contexts $C$ and the target call context $t$, the \textit{best context similarity} is
    maximum of all context similarities among each call context in $C$ and the target $t$.
\end{definition}

\begin{definition}
    Given an execution trace $e$ and a list of control dependencies $D$, the \textit{TEMP approach level} is the
    approach level of $e$ in respect to the inner-most control dependency in $D$.
\end{definition}

A test case, during its execution, may employ multiple call contexts (some of them more than once) and the fitness function
checks whether there is perfect match (\textit{i.e.,} when best context similarity is $1$);
if there is no perfect match, the fitness is set to $2 - bestContextSimilarity$, while if there is at
least one match, the TEMP approach level is computed and the fitness is set to $tempApproachLevel / \#goals$.
In case of no control dependencies at all, the fitness is set to $0$.
Finally, the fitness score of the entire test suite is set to $1 - coveredGoals/\#goals$.
Whenever the suite's score is minimized to $0$ all vulnerabilities are considered exploited and the search stops with success.

\subsection{Genetic Operators}\label{subsec:operators}
\textbf{Currently I have not modified any genetic operators, but I will give a try to improve performance once I have a stable idea}

\subsection{Measuring the Effort}\label{subsec:effort}
\textbf{I will implement a "effort" mechanism, that measures how hard was a certain goal once I have a stable idea}

%! Author = emaia
%! Date = 10/03/20

In this section we explain the novel search algorithm used for the automatic generation of exploit test cases.

\subsection{Context}\label{subsec:assumptions}
% Dataset
We chose to analyze the vulnerabilities of well-known OSS Java libraries and frameworks (\textit{e.g.,} Spring, Jenkins, Tomcat, Kafka, etc.),
publicly disclosed as CVE entries and collected in the NVD. In particular, \citeauthor{ponta2019msr_dataset},
defined and made available a manually-curated dataset of about 1000 known
vulnerabilities~\cite{ponta2019msr_dataset}.
This dataset maps for each CVE entry the related repository URL (the vast majority of
the involved projects are hosted on GitHub) and the hash of the fix commit
(\textit{i.e.,} the commit that officially patches the vulnerability).
So, the dataset has the form of a set of triples \textit{(CVE\_entry, repository\_url, fix\_commit\_hash)}, for example
(CVE-2017-4971, \url{https://github.com/spring-projects/spring-webflow}, 57f2ccb).
The fix commits are very different from each other: some of them apply changes on few lines in a single class,
while others consists of adding, removing and/or modifying entire methods in several classes.
Given a vulnerability, we can obtain the set of vulnerable constructs by looking at which ones were impacted
by the changes of the fix commit~\cite{ponta2018icsme_beyond}

% Assumptions
We chose to focus on what we consider the most simple type of vulnerable construct, that is the vulnerable line,
so the proposed coverage criterion is a variant of line coverage.
When this approach is mature enough, we will extend it to other types of vulnerabilities.

% Evosuite: why extend
We chose to implement this novel algorithm as an extension of \textsc{EvoSuite}~\cite{fraser2013_evosuite},
an automatic \textit{JUnit} test case generator for \textit{Java} classes that uses a whole suite GA to derive
the best possible test suite (namely, covering all feasible goals and having the minimal number of total statements).
\textsc{EvoSuite} is a fully-fledged GA framework, so it allows to (i) add new coverage criteria,
(ii) add new genetic operators (\textit{i.e.,} selection, crossover and mutation), (iii) reuse well-validated meta-heuristics and
(iv) reuse the instrumentation and program analysis tools, such as Control Flow Graphs, Call Graphs and Execution Traces.
It is possible to extend \textsc{EvoSuite} by adding some classes (related to the new coverage criteria and genetic operators),
and make small changes in others.
Sections~\ref{subsec:goals} and~\ref{subsec:fitness} provide additional details on the search algorithm.

In the context of this work we are not generating tests in the narrow sense of the term
(\textit{i.e.,} a program execution that verifies a certain
expected behaviour) but `exploits cases', so we will ignore the assert generation engine.

\subsection{Coverage Goals}\label{subsec:goals}
A coverage goal for this novel algorithm is defined from a triple of strings $\langle$\textsc{vulnerable\_class}, \textsc{vulnerable\_method},
\textsc{vulnerable\_line}$\rangle$ where \textsc{vulnerable\_class} is the fully-qualified name of the vulnerable class (\textit{e.g.,}
\sloppy\textit{hudson.tasks.Mailer}), \textsc{vulnerable\_method} is the name of the vulnerable
method concatenated with its descriptor (\textit{e.g.,} \sloppy\textsc{matches([B[B)Z})
and \textsc{vulnerable\_line} is the number of the vulnerable line in the source code.
The strings \textsc{vulnerable\_class} and \textsc{vulnerable\_method} are used to determine the \textit{call context},
\textit{i.e.,} the list of method calls from the class under test (CUT) required to statically reach the vulnerable method in the vulnerable class;
the string \textsc{vulnerable\_line} is used to retrieve the list of control dependencies on the vulnerable line
\textit{i.e.,} the set of branches to be satisfied in order to reach the block containing the line.

In other words, each coverage goal is composed of (i) a \textit{target call context} to reach the vulnerable method and
(ii) the \textit{target list of control dependencies} required to execute the vulnerable line.
An individual (test suite) \textit{covers a goal} whenever it has a test case whose execution trace covers the call context and all
control dependencies in the list.

\subsection{Fitness Function}\label{subsec:fitness}
The computation of the fitness score of a test case is based on
the \textit{context similarity} and \textit{approach level} measures:

\begin{definition}
    Given two call contexts $ctx$ and $tar$, the \textit{context similarity} is the ratio
    of the number of method calls that $ctx$ and $tar$ have in common out the total number of the longest call context.
\end{definition}

A test case's execution trace covers various call contexts, so the \textit{best context similarity}
is the maximum of all context similarities that can be computed with respect to the same target call context.

\begin{definition}
    Given an execution trace $ex$ and a branch $br$, the \textit{approach level} is the number of
    control dependencies between $br$ and the branch that is executed by $ex$ and closest to $br$ .
\end{definition}

This definition can be extended to a list of branches (\textit{i.e.,} control dependencies), so the
\textit{best approach level} is the approach level of the execution trace with respect to the innermost control dependency.

Given a test case's execution trace, the fitness function starts computing the best context similarity,
and if there is a perfect match (\textit{i.e.,} best context similarity is equals to $1$) it proceeds to compute
the best approach level and set its score to the best approach level divided to the total number of target control dependencies;
if there is no perfect match, the fitness score is set to $2 - bestContextSimilarity$; if there no control dependencies at all,
the perfect match is enough to set the score to $0$ (optimum value).
The fitness score $0$ flags the goal as covered.

The fitness scores of a test suite is set to the minimum fitness score among all its test cases;
this implies that having a single test case that covered the goal is enough to flag the entire test suite as best individual.

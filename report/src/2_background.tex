%! Author = emaia
%! Date = 14/03/20

In this section we briefly introduce the concept of genetic algorithm (GA)
and some well-known implementations in literature.

% SBSE
SBSE focuses on using search algorithms and techniques to solve Software Engineering-related problems~\cite{anand2013jss_survey};
in particular, Search-Based Software Testing (SBST) makes an extensive use of these techniques for solving problems
like Test Case Generation, Selection or Prioritization.
One of the most prominent problem in software testing is providing a minimal-cost test suite that maximizes a certain
criterion (\textit{e.g.,} covering the largest number of branches).
Generating test cases (often only the test input data) means using search algorithms guided by a
\textit{fitness function} that models a set of \textit{test goals} (\textit{a.k.a.,} test objectives).
The fitness function guides the search in the space of test cases to find those that best meet the test
goals;
this approach is highly generic and widely applicable is various forms.
There are many different kinds of search techniques, but in recent years the literature has been working on evolutionary approaches, in particular GAs.

\subsection{Genetic Algorithms}\label{subsec:genetic}
% GA: meta-heuristic
A GA is a particular type of a meta-heuristic optimisation algorithm (\textit{i.e.,} a general technique that can be applied to a broad range of search problems).
It starts with an initial random \textit{population} of \textit{individuals} (\textit{a.k.a.,} chromosomes),
which are candidate solutions for the given problem and whose genetic structure depends on the specific problem representation.
The population starts to evolve by passing through different generations (iterations) that continuously change its individuals
in order to produce the best solutions;
in a single iteration each individual is given to the fitness function that produces a score that represents its chance of surviving.
The evolution consists of applying various operators on individuals, such as (i) \textit{selection}, that choose
the best individuals (the higher the fitness score, the higher the probability to be chosen) for the creation of the next generation of individuals;
(ii) \textit{crossover}, that applies some \textit{genes} interchange to each pair of selected \textit{parents} to generate their \textit{offsprings},
that will be added in the next generation;
(iii) \textit{mutation}, that randomly changes some genes of the newly-formed offsprings with a certain probability.
There may be different termination criteria: (i) the search budget (\textit{e.g.,} running time) may expire;
(ii) the population may reach the convergence (\textit{i.e.,} it has an individual with perfect fitness) or
(iii) the algorithm may stop making progresses, meaning that for some iterations the aggregate fitness score (related to the entire population) had no improvements.

% GA: Single vs Many
Typically, a fitness function is expressed in terms of a minimum function (\textit{i.e.,} the optimal value is the function's absolute minimum).
While common implementations use a single fitness function (\textit{a.k.a.,} single-objective optimisation), others prefers using multiple, often
conflicting, functions (\textit{a.k.a.,} many-objective optimisation), implying a redefinition of the concept of optimality that takes into
account multiple fitness scores --- collected into a \textit{fitness vector} --- and their trade-offs.
In many-objective problems we use the broader concepts of \textit{Pareto dominance} and \textit{Pareto optimality}~\cite{deb2005moo}.
%meaning that an individual is better
%than another one when it \textit{dominates} it, \textit{i.e.,} when it has at least one better fitness score than the other
%individual while the other scores are not worse than the other's.

\begin{definition}
    An individual $x$ \textit{dominates} another individual $y$ (also
    written $x \prec y$) if and only if the values of the fitness vector
    satisfy the following conditions:
    $\forall i \in \{1, \ldots, k\}, f_i(x) \leq f_i(y)$ and
    $\exists j \in \{1, \ldots, k\}, f_j(x) < f_j(y)$,
    where $k$ is the number of fitness functions.
\end{definition}

\begin{definition}
    An individual $x^*$ is \textit{Pareto optimal} if and only if it is not
    not dominated by any other individual in the space of all possible
    individuals (feasible region).
\end{definition}

\begin{definition}
    The \textit{Pareto front} is the set of all Pareto optimal individuals.
\end{definition}

% GA: in SBST
In Test Case Generation problem, a test suite is modeled as a population of evolving test cases (individuals),
which are, simply speaking, described as a list of statements and values (genes).
The test goals, that will define the fitness function(s), depend on the chosen \textit{coverage criterion}, that is commonly a
coverage measure from white-box testing, such as branch, line or mutation coverage.
The fitness function(s) will be based on how much the execution trace of a test case is close from the aforementioned goals;
for instance, for branch coverage the fitness is based on the number of control dependencies that separate the execution trace
from the target branch (\textit{approach level}) and on the variable values evaluated at the conditional expression where the execution
diverges from the target (\textit{branch distance})~\cite{panichella2018tse_dynamosa}.

\subsection{Notable Implementations}\label{subsec:implementations}
The various forms of fitness functions are not the only variants that can be applied on GAs;
indeed, there are numerous examples in literature of how malleable a GA is.

% MOSA: preference and archive
\citeauthor{panichella2015icst_mosa}~\cite{panichella2015icst_mosa} proposed MOSA (Many-Objective Sorting Algorithm),
which uses multiple fitness functions, one for each branch of the SUT (any other coverage criterion is valid),
to generate the best set of Pareto optimal test cases that minimize all the fitness functions.
In many-objective problems, however, the number of (Pareto) optimal individuals increases exponentially with the number of objectives,
making the search much more difficult (\textit{i.e.,} the convergence is hardly reached) and
the algorithm to perform similarly to a random search one.
Thus, domain-specific knowledge is required to impose some \textit{preference criteria} among the set of non-dominated test cases;
for example in test case generation problem test cases (i) that cover (or are close to) yet uncovered targets and
(ii) that are smaller than its competitors are preferred over others.
As consequence, the set of candidate (for reproduction) individuals is a subset of the whole Pareto front.
In addition to these preference criteria, MOSA adds the \textit{archive} technique, that consists of keeping a distinct
non-evolving population containing the test cases that satisfy previously uncovered targets;
after the final iteration, the test cases are picked from both the last population and the archive to form the final test suite.

% DynaMOSA: dynamic selection of targets
The main limitation of MOSA is that it treats all coverage goals as independent objectives, when, actually,
there exist structural dependencies among them that should be considered when deciding which one to optimise;
for example a certain branch could be satisfied if all branches that hold a control dependency on it have already been covered.
To overcome this limitation, the same main author of MOSA proposed DynaMOSA (Dynamic MOSA)~\cite{panichella2018tse_dynamosa}
that is able, in each iteration, to \textit{dynamically select targets} whose control dependency holders have already been covered in previous
iterations and to ignore the other targets.
This idea makes the search more effective and efficient in situations where there are a lot of dependencies among coverage goals.

% MIO: independent evolutionary algorithm
A quite different optimisation approach is with MIO (Many Independent Objectives)~\cite{arcuri2017lncs_mio}, an evolutionary algorithm
that works well for hundreds/thousands of independent (though not incompatible) goals.
It keeps one population for each goal --- called \textit{islands} --- that evolves independently from the others
(namely, the individuals of an island are only evaluated against the respective fitness function).
The reproduction mechanism is not based on genetic operators (this is why MIO is not classified as a GA), but rather on sampling individuals either
randomly or from other islands (\textit{i.e., migration}).
Whenever a goal is covered, its island stops evolving and only the best individual survives;
at the end of the entire search, the set of best individuals forms the final solution.

% Co-evolutionary: COMIX
The MIO approach can be combined with GAs, creating the so-called class of \textit{co-evolutionary} algorithms,
that consists of a set of islands that evolve independently but using standard genetic operators with some periodical migrations (though with some variations).
An example of a co-evolutionary algorithm is COMIX (Cooperative Co-evolutionary Algorithm for XMLi)~\cite{jan2019_xmli},
used for the automatic generation of malicious user inputs that exploit XML Injection vulnerabilities in web applications.
An important difference between COMIX and the other aforementioned algorithms is that the goals are not based on
the typical coverage measures from white-box testing, but, instead, they are based on a precise set of malicious XML messages, making the strategy totally black-box.

% Evosuite: Whole suite
\citeauthor{fraser2013_evosuite} in the context of \textsc{EvoSuite}~\cite{fraser2013_evosuite} proposed
the \textit{whole suite approach} that changes the point of view:
instead of evolving a population of test cases, it evolves a population of test suites and the single
fitness function models all the coverage goals at once.
The fitness score of a single test suite is an aggregation of the fitness `sub-scores' of each composing test case.
Moreover, the \textsc{EvoSuite}'s algorithm has a preference for smaller test suite, --- namely, it tries to find the test suite
with the minimal number of total statements among all individuals.
\textsc{EvoSuite} tool supports multiple coverage criteria, such as branch, method, line, def-use, mutation, exceptions, etc.
and it is able to \textit{generate regression assertions} (\textit{i.e.,} test oracles) for each produced test case of the final test suite, too.

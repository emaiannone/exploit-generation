%! Author = emaia
%! Date = 14/03/20

\textbf{WORK IN PROGRESS SECTION}

In this section we briefly introduce the concept of genetic algorithms in Search-Based Software Engineering (SBSE) and some well-known implementations in literature.

% SBSE
SBSE focuses on using search algorithms and techniques to solve Software Engineering-related problems~\cite{anand2013jss_survey};
in particular, Search-Based Software Testing (SBST) makes an extensive use of these techniques for solving problems
like Test Case Generation, Selection or Prioritization.
One of the most prominent problem in software testing is providing a minimal-cost test suite that maximizes a certain
criterion (\textit{e.g.,} covering the largest number of branches).
Generating test cases (sometimes only their input) means using search algorithms guided by a
\textit{fitness function} that models a set of \textit{test goals} (\textit{a.k.a.,} test objectives).
The fitness function guides the search in the space of test cases to find those that best meet the test
goals;
this approach is highly generic and widely applicable is various forms.
There are many different kinds of search techniques, but in recent years the literature has been working on evolutionary approaches, in particular genetic algorithms.

\subsection{Genetic Algorithms}\label{subsec:genetic}
% GA: meta-heuristic
A genetic algorithm is a particular type of a meta-heuristic optimization algorithm, \textit{i.e.,} a general technique that can be applied to a broad range of search problems.
It starts with an initial random \textit{population} of \textit{individuals} (\textit{a.k.a.,} chromosomes),
which are candidate solutions for the given problem and whose genetic structure depends on the specific problem representation.
The population starts to evolve by passing through different iterations (generations) that continuously change its individuals
in order to produce the best solutions;
in a single iteration each individual is given to the fitness function that produces a score that represents its chance of surviving in the evolution.
The evolution consists of applying various operators on individuals, such as (i) \textit{selection}, that choose
the best individuals (the higher the fitness score, the higher the probability to be chosen) for the creation of the next generation of individuals;
(ii) \textit{crossover}, that applies some \textit{genes} interchange to each pair of selected \textit{parents} to generate their \textit{offsprings},
that will be added in the next generation;
(iii) \textit{mutation}, that randomly changes some genes of the newly-formed offsprings with a certain probability.
There may be different termination criteria: (i) the search budget (\textit{e.g.,} time) expires;
(ii) the population reaches the convergence (\textit{i.e.,} it has an individual with perfect fitness) or
(iii) the algorithm makes no progresses, meaning that for some iterations the aggregate fitness score (related to the entire population) made no improvements.

% GA: Single vs Many
Typically, a fitness function is expressed in terms of a min function (\textit{i.e.,} the optimal value is the minimum).
While common implementations use a single fitness function (single-objective), others prefers using multiple, often
conflicting, functions (many-objective), implying a redefinition of the concept of optimality that takes into
account multiple fitness scores --- collected in a \textit{fitness vector} --- and the trade-offs.
In many-objective contexts we use the broader concept of \textit{Pareto optimality}~\cite{deb2005moo}, meaning that an individual is better
than another one when it \textit{dominates} it, \textit{i.e.,} when it has at least one better fitness score than the other
individual while the other scores are not worse than the other's. \textbf{I don't like this sentence, should I use some formulas?
DynaMosa paper has some}

% GA: in SBST
In Test Case Generation, a test suite is modeled as a population of evolving test cases (individuals), which are
composed of a list of statements (genes).
The test goals, that will define the fitness function(s), depend on the chosen \textit{coverage criteria}, that is commonly a
coverage measure from white-box testing, such as branch, line or mutation coverage.
The fitness function(s) will be based on how much the execution trace of a test case is distant from the aforementioned goals;
for instance, for branch coverage the distance is based on the number of control dependencies that separate the execution trace
from the target branch (\textit{approach level}) and on the variable values evaluated at the conditional expression where the execution
diverges from the target (\textit{branch distance})~\cite{panichella2018tse_dynamosa}.

\subsection{Notable Examples}\label{subsec:examples}
The various forms of fitness functions are not the only variants that can be applied on genetic algorithms;
indeed, in literature there are numerous examples of how malleable a genetic algorithm is.

\citeauthor{panichella2015icst_mosa}~\cite{panichella2015icst_mosa} proposed MOSA (Many-Objective Sorting Algorithm),
which uses multiple fitness function --- one per each branch of the SUT (any other coverage criteria is valid) ---,
to generate the best set of non-dominated (Pareto optimal) test cases that minimize all the fitness functions, \textit{a.k.a.,} the \textit{Pareto front}.
In many-objective problems, however, the number of non-dominated individuals increases exponentially with the number of objectives,
making the search much more difficult (\textit{i.e.,} the convergence is hardly reached) and the algorithm performs like a random search one.
Thus, domain specific knowledge is needed to impose some \textit{preference criteria} among non-dominated test cases;
for test case generation, this means preferring test cases that (i) cover (or are close to cover) uncovered targets and
(ii) are smaller than other competitors, so, for each test goal, the best individual is the closest and smallest one.
As consequence, the set of candidate (for reproduction) individuals is a subset of Pareto front.
%, \textit{i.e.,} the set of all best test cases.
In addition to these preference criteria, MOSA adds the \textit{archive} technique, that consists of keeping a second
non-evolving population of test cases.
Specifically, whenever new test cases are generated MOSA stores in the archive those individuals that satisfy previously
uncovered targets;
after the final iteration, the test cases are picked from both the last population and the archive to form the final test suite.

One limitation of MOSA is that ... \textbf{continue from dynamosa}

- DynaMOSA (briefly on dynamic selection)
- MIO (independent populations)
- EvoSuite con più dettaglio (Wholesuite approach. Take some info from 3. Dire solo brevemente che supporta molteplici coverage goal e dire brevemente che è estendibile e rimandare alla sez. 3 per come è stato esteto in questo lavoro)
- COMIX per XML Injection (coverage goal not a coverage measure of white-box)

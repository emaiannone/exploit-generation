import csv
import logging
import os
import re
import shutil
from pprint import pprint

from git import GitCommandError
from pydriller import RepositoryMining, Commit


def parse_csv():
    """
    Converts the dataset.csv file into a list of dicts

    :return: a list of dicts with 'cve', 'repo' and 'commit_hash' values.
    """
    with open('dataset.csv') as csv_file:
        csv_reader = csv.reader(csv_file, delimiter=',')
        return [{"cve": row[0], "repo": row[1], "commit_hash": row[2]} for row in csv_reader]


def is_single_java(c: Commit) -> bool:
    """
    Checks if the given commit modify a single Java file.

    :param c: commit object with commit info
    :return: true iff the given commit object modify a single java file
    """
    mods_java = [mod for mod in c.modifications if re.match(r'.*\.java', mod.filename)]
    return len(mods_java) == 1


def clean_local_repo(repo_url):
    """
    Remove the directory of the cloned repository, if it exists.
    :param repo_url: URL of the remote repository
    :return:
    """
    project_name = repo_url[repo_url.rfind('/') + 1:]
    if os.path.exists('/tmp/' + project_name):
        shutil.rmtree('/tmp/' + project_name)


# Change values here
from_entry = 1001
to_entry = 1278

logging.basicConfig(filename='log.log', level=logging.CRITICAL)
entries = parse_csv()
"""
entries = [{
    "cve": "CVE-XXX-YY",
    "repo": "https://github.com/apache/tomcat85",
    "commit_hash": "46ee39d64b308da10aeef899e30b4dfeefe25bf4"
}, {
    "cve": "CVE-ZZZ-WW",
    "repo": "https://github.com/emaiannone/aDoctor",
    "commit_hash": "419d4544a9b52a4fd5af0edab8bd28f97bef9b72"
}, {
    "cve": "CVE-ZZZ-WW",
    "repo": "https://github.com/apache/tomcat85",
    "commit_hash": "419d4544a9b52a4fd5af0edab8bd28f97bef9b73"
}
]
"""

repos = []
for entry in entries[from_entry:to_entry + 1]:
    repo_urls = [repo["url"] for repo in repos]
    try:
        i = repo_urls.index(entry["repo"])
        repos[i]["hashes"].append(entry["commit_hash"])
    except ValueError:
        repos.append({
            "url": entry["repo"],
            "hashes": [entry["commit_hash"]]
        })
pprint(repos)

single_java_vuln_commits = []
for repo in repos:
    repo_url = repo["url"]
    clean_local_repo(repo_url)
    print(f'Cloning {repo_url} ...', end=' ')
    try:
        repo_mining = RepositoryMining(repo_url,
                                       clone_repo_to="/tmp",
                                       order='reverse',
                                       only_in_branch='master')
    except GitCommandError as e:
        print('cannot mine. Skipping.')
        logging.error(e)
    else:
        try:
            commits = list(repo_mining.traverse_commits())
            print("done!")
            vuln_commits = [c for c in commits if c.hash in repo["hashes"]]
            if vuln_commits:
                for vc in vuln_commits:
                    if is_single_java(vc):
                        head_msg = vc.msg.split("\n", 1)[0]
                        single_java_vuln_commits.append({
                            "project": repo_url,
                            "hash": vc.hash
                        })
                        print(f'\t{vc.hash} is interesting!')
                    else:
                        print(f'\t{vc.hash} found but not interesting.')
            else:
                print('\tcommit(s) not found :(')
        except GitCommandError as e:
            print("repository not found or local directory is not empty. Skipping.")
            logging.error(e)
        finally:
            clean_local_repo(repo_url)

if len(single_java_vuln_commits) > 0:
    with open(f'interesting_vulnerabilities{from_entry}-{to_entry}.csv', 'w') as interesting_file:
        dict_writer = csv.DictWriter(interesting_file, single_java_vuln_commits[0].keys())
        dict_writer.writeheader()
        dict_writer.writerows(single_java_vuln_commits)
